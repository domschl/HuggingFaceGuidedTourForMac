{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47040240-fa7e-431b-924f-02ef1696779b",
   "metadata": {},
   "source": [
    "# Installed software check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29867cbd-8ba7-47ce-afd3-c38f5bc1091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 2.7.1\n",
      "Apple Metal MPS acceleration ok.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    print(f\"Pytorch version: {torch.__version__}\")\n",
    "    is_torch = True\n",
    "    if torch.backends.mps.is_available() is True:\n",
    "        print(\"Apple Metal MPS acceleration ok.\")\n",
    "    else:\n",
    "        print(\"Your version of Pytorch does not support MPS, Pytorch will be slow.\")\n",
    "except:\n",
    "    print(\"Pytorch is not installed. Please install pytorch!\")\n",
    "    is_torch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f22a840-d023-438d-b5c2-0539d7fe19ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLX version: 0.26.1\n",
      "Apple MLX framework is installed ok\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import mlx.core as mx\n",
    "    print(f\"MLX version: {mx.__version__}\")\n",
    "    is_mlx = True\n",
    "    print(\"Apple MLX framework is installed ok\")\n",
    "except:\n",
    "    print(\"MLX is not installed, it's optional, so this is not a fatal error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db547c2-4f6f-4016-8719-887a89f3be66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.19.0\n",
      "GPU support ok: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"Tensorflow version: {tf.__version__}\")\n",
    "    is_tensorflow = True\n",
    "    devs=tf.config.list_physical_devices('GPU')\n",
    "    if devs is None or len(devs)==0:\n",
    "        print(\"You have not installed the metal drivers, tensorflow will be slow\")\n",
    "    else:\n",
    "        print(f\"GPU support ok: {devs}\")\n",
    "except:\n",
    "    print(\"Tensoflow not installed, but it's optional, so this is not a fatal error.\")\n",
    "    is_tensorflow = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17fc1919-f641-4cd0-968a-b7c1738059cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Max\n",
      "JAX is installed and is using: Metal, ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1750593923.041878 5224214 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1750593923.042632 5224214 service.cc:145] XLA service 0x600001a74600 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1750593923.042643 5224214 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1750593923.047852 5224214 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1750593923.047871 5224214 mps_client.cc:384] XLA backend will use up to 22905061376 bytes on device 0 for SimpleAllocator.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import jax\n",
    "    is_jax = True\n",
    "    device_type = jax.devices()[0].device_kind\n",
    "    print(f\"JAX is installed and is using: {device_type}, ok\")\n",
    "except:\n",
    "    print(\"JAX is not installed, it's optional, so this is not a fatal error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf367403-bbcd-4841-a59b-66ead3dd1697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.52.4\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import transformers\n",
    "    from transformers import pipeline\n",
    "    print(f\"Transformers version: {transformers.__version__}\")\n",
    "    is_huggingface = True\n",
    "except Exception as e:\n",
    "    print(f\"HuggingFace transformers is not installed. This won't work! {e}\")\n",
    "    is_huggingface = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197a353a-01bb-4ec4-b6be-9bfffda2c568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All looks good, let's try a simple sentiment analysis:\n"
     ]
    }
   ],
   "source": [
    "if is_huggingface is False or is_torch is False:\n",
    "    print(\"The minimal software is not installed. Please check that PyTorch and HuggingFace are installed, following the HowTo!\")\n",
    "    print(\"At this stage, non of the examples will work!\")\n",
    "    print(\"\")\n",
    "    print(\"Hint: all software installed with `pip` needs to be installed into the same active environment,\")\n",
    "    print(\"otherwise components won't see each other.\")\n",
    "else:\n",
    "    print(\"All looks good, let's try a simple sentiment analysis:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3114971-5678-4c9f-8b2e-a618eecc2513",
   "metadata": {},
   "source": [
    "## Sentiment analysis minimal example\n",
    "\n",
    "> **Note:** when this pipeline is run for the first time, several hundred megabytes of models are downloaded once. The files downloaded are at `~/.cache/huggingface`. You can remove those resources at any time, and they will be re-downloaded if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07521c38-02bb-4b12-b336-d068ca4d5442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = pipeline(\"sentiment-analysis\", framework='pt')\n",
    "nlp(\"We are very happy to show you the ðŸ¤— Transformers library.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19962824-6493-4bdd-8446-dc1916720fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.52.4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc728f-dc27-49de-bbef-e4b0102cfedd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
